{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6zBvJP+AHck6bCggls3ox",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yc-chen10/113-1-finance/blob/main/week10%E4%BD%9C%E6%A5%AD_%E9%87%91%E8%9E%8D%E6%96%87%E6%9C%AC%E6%83%85%E7%B7%92%E8%BE%A8%E8%AD%98Hugging_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "qTxw4S6XOKRz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要套件\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch"
      ],
      "metadata": {
        "id": "Gi-1UhZgOisP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. 載入資料集\n",
        "dataset = load_dataset(\"takala/financial_phrasebank\", \"sentences_allagree\")"
      ],
      "metadata": {
        "id": "YpREu6vROlN-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 分詞器初始化\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 3. 分詞函數\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"sentence\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# 4. 數據分詞並轉換為 PyTorch 格式\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
        "tokenized_datasets.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
      ],
      "metadata": {
        "id": "-uoryazeOn1t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 劃分訓練集和測試集（80%訓練，20%測試）\n",
        "train_test_split = tokenized_datasets[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "tokenized_datasets = DatasetDict({\n",
        "    \"train\": train_test_split[\"train\"],\n",
        "    \"test\": train_test_split[\"test\"]\n",
        "})\n",
        "\n",
        "# 6. 檢查數據集\n",
        "print(f\"Training sample: {tokenized_datasets['train'][0]}\")\n",
        "print(f\"Test sample: {tokenized_datasets['test'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVK-XYGrOou6",
        "outputId": "40c76111-d491-4bf5-93f0-208e19ecb4b3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sample: {'labels': tensor(1), 'input_ids': tensor([  101, 12849,  4246,  1005,  1055,  3006,  3745,  1997,  1996,  3872,\n",
            "         1997,  1996,  3006,  2001,  2603,  1012,  1018,  1003,  1010, 10556,\n",
            "        25032,  2226,  1005,  1055,  2538,  1012,  1018,  1003,  1012,   102,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n",
            "Test sample: {'labels': tensor(1), 'input_ids': tensor([  101, 22472,  1998,  2061,  8202,  9006,  3710,  4261,  2581,  1010,\n",
            "         2199, 17073,  1998,  2018,  1037,  3006,  3745,  1997,  3155,  2676,\n",
            "         1003,  2004,  1997,  2089,  2289,  1012,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 初始化 BERT 模型（3分類：Negative, Neutral, Positive）\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A20TtytAOrnd",
        "outputId": "baef0768-5ba5-4989-b40c-f6c9f2c37d7d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. 評估函數\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = torch.argmax(torch.tensor(logits), axis=-1).numpy()\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    print(classification_report(labels, predictions, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
        "    return {\"accuracy\": acc}"
      ],
      "metadata": {
        "id": "Ikl-NZ2rOvED"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. 訓練參數\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    run_name=\"financial_sentiment_analysis\"\n",
        ")\n",
        "\n",
        "# 10. 設置 Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlqKEFH0OyHV",
        "outputId": "4ee2cf8a-fb7d-4060-8d4c-15ca924a0041"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-14-09492d3ca354>:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. 訓練模型\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "H3_Sa51zO0Sq",
        "outputId": "81c8e5cf-b66f-4c94-9c07-83e3431b8d4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [342/342 2:04:57, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.237700</td>\n",
              "      <td>0.194457</td>\n",
              "      <td>0.951435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.097000</td>\n",
              "      <td>0.149327</td>\n",
              "      <td>0.966887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.016900</td>\n",
              "      <td>0.149302</td>\n",
              "      <td>0.966887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      0.90      0.92        73\n",
            "     Neutral       0.98      0.98      0.98       280\n",
            "    Positive       0.89      0.91      0.90       100\n",
            "\n",
            "    accuracy                           0.95       453\n",
            "   macro avg       0.93      0.93      0.93       453\n",
            "weighted avg       0.95      0.95      0.95       453\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.94      0.93      0.94        73\n",
            "     Neutral       0.99      0.98      0.99       280\n",
            "    Positive       0.92      0.95      0.94       100\n",
            "\n",
            "    accuracy                           0.97       453\n",
            "   macro avg       0.95      0.95      0.95       453\n",
            "weighted avg       0.97      0.97      0.97       453\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.94      0.93      0.94        73\n",
            "     Neutral       0.99      0.98      0.99       280\n",
            "    Positive       0.92      0.95      0.94       100\n",
            "\n",
            "    accuracy                           0.97       453\n",
            "   macro avg       0.95      0.95      0.95       453\n",
            "weighted avg       0.97      0.97      0.97       453\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=342, training_loss=0.21215787525043675, metrics={'train_runtime': 7532.5294, 'train_samples_per_second': 0.721, 'train_steps_per_second': 0.045, 'total_flos': 357373799629056.0, 'train_loss': 0.21215787525043675, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. 評估模型\n",
        "results = trainer.evaluate()\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Eu5tRvv9O2wL",
        "outputId": "b1381e7d-52eb-44db-dced-b321fc641b49"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [29/29 02:40]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.94      0.93      0.94        73\n",
            "     Neutral       0.99      0.98      0.99       280\n",
            "    Positive       0.92      0.95      0.94       100\n",
            "\n",
            "    accuracy                           0.97       453\n",
            "   macro avg       0.95      0.95      0.95       453\n",
            "weighted avg       0.97      0.97      0.97       453\n",
            "\n",
            "{'eval_loss': 0.14930245280265808, 'eval_accuracy': 0.9668874172185431, 'eval_runtime': 167.4421, 'eval_samples_per_second': 2.705, 'eval_steps_per_second': 0.173, 'epoch': 3.0}\n"
          ]
        }
      ]
    }
  ]
}